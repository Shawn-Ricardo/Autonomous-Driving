{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers.convolutional. import Convolutional2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Cropping2D\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# open CSV file containing paths to simulator images\n",
    "data_paths = []\n",
    "with open('driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        data_paths.append(line)\n",
    "\n",
    "# populate containers to hold images and corresponding steering angles\n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "for line in data_paths:\n",
    "    \n",
    "    # read in center, left, and right camera images from simulator\n",
    "    for i in range(3):\n",
    "        source_path = line[i]\n",
    "        tokens = source_path.split('/')\n",
    "        filename = tokens[-1]\n",
    "        local_path = \"IMG/\" + filename\n",
    "\n",
    "        # load the image in the BGR format and convert to YUV\n",
    "        image = cv2.cvtColor(cv2.imread(local_path, CV_LOAD_IMAGE_COLOR), cv2.COLOR_BGR2YUV)\n",
    "        \n",
    "        images.append(image)\n",
    "    \n",
    "    # correction to apply to left and right camera images\n",
    "    correction = 0.015\n",
    "    \n",
    "    # get the steering angle recorded during simulator driving\n",
    "    measurement = float(line[3])\n",
    "    \n",
    "    # don't add correction to center camera image\n",
    "    measurements.append(measurement)\n",
    "    \n",
    "    # steer more to the right for left camera images\n",
    "    measurements.append(measurement + correction)\n",
    "    \n",
    "    # steer more to the left for right camera images\n",
    "    measurements.append(measurement - correction)\n",
    "    \n",
    "# flip the images in order to simulate driving the reverse direction on the track\n",
    "# note: this process can be combined with the loop above, but its\n",
    "# written here for clarity of the process.\n",
    "# 2nd note: more image preprocessing can be done here, like image warping, if desired.\n",
    "augmented_images = []\n",
    "augmented_measurements = []\n",
    "for image, measurement in zip(images, measurements):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    flipped_measurement = float(measurement) * -1.0\n",
    "    augmented_images.append(flipped_image)\n",
    "    augmented_measurements.append(flipped_measurement)\n",
    "    \n",
    "# cast the training data set into numpy arrays\n",
    "x_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)\n",
    "\n",
    "# get model\n",
    "model = Sequential()\n",
    "\n",
    "# The inputs are YUV, having values between 0 and 255.\n",
    "# Normalize the inputs between a range of 0 and 1 by dividing by 255.\n",
    "# Subtracting by 0.5 will shift mean from 0.5 to 0.\n",
    "# Normalizing the data helps the network learn more efficiently.\n",
    "# The input shape of the image is 160x320 with 3 color channels for YUV\n",
    "model.add(Lambda(lambda X: x / 255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "\n",
    "# Crop the image to only show relevant pixels (crop out trees, mountains, and the hood of the car)\n",
    "# that are critical to the network. Just the road itself.\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "# The following network architecture was taken from the paper,\n",
    "# \"End to End Learning for Self-Driving Cars\" by several engineers\n",
    "# at Nvidia. The paper can be accessed here:\n",
    "# http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "\n",
    "model.add(Convolution2D(24,5,5,subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(36,5,5,subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(48,5,5,subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3,activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1164))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# implement the Adam optimizer\n",
    "adamOpt = keras.optimizers.Adam(lr=0.001, beta_l=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='mse', optimizer=adamOpt)\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=10)\n",
    "\n",
    "model.save(\"model.h5\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
